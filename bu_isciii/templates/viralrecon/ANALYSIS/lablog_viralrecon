# module load singularity

# If there is more than 1 reference, please prepare the samples_ref.txt file before running this lablog.

####################################
# Defining functions

# Coloring messages
echo_bold() { echo -e "\e[1;37m$1\e[0m"; }
echo_red() { echo -e "\e[1;31m$1\e[0m"; }
echo_green() { echo -e "\e[1;32m$1\e[0m"; }
echo_blinking_red() { echo -e "\e[1;5;97;5;41m$1\e[0m"; }


# Updating pangolin. Checks last image available and if is already downloaded. If not, downloads it. This function also updates pangolin database. Update related config files with pangolin info
update_pangolin() {
    echo "Checking Pangolin container version..."
    url=$(curl -s "https://depot.galaxyproject.org/singularity/")
    latest_version_pangolin=$(echo "$url" | grep -oP 'pangolin:[^"]+' | sort -V | tail -n 1 | awk -F'>' '{print $1}' | sed 's/<\/a//')
    echo "Latest version available of Pangolin: $latest_version_pangolin."

    echo "Checking if latest version of Pangolin image is already downloaded..."
    if [ -e "/data/bi/scratch_tmp/bi/singularity-images/$latest_version_pangolin" ]; then
        echo "File $latest_version_pangolin already downloaded."
        echo "Pangolin database UP TO DATE."
    else
        echo "Downloading $latest_version_pangolin file..."
        wget -P "/data/bi/scratch_tmp/bi/singularity-images/" "https://depot.galaxyproject.org/singularity/$latest_version_pangolin"
        echo "$latest_version_pangolin file succesfully downloaded."
    fi

    # Updating Pangolin database
    echo "Setting datadir for Pangolin database."
    cd /data/bi/references/pangolin/
    if [ -e "./$(date '+%Y%m%d')" ]; then
        echo "Pangolin database is UP TO DATE"
    else
        mkdir "$(date '+%Y%m%d')"
        srun --partition short_idx singularity run -B ${PWD} /scratch/bi/singularity-images/$latest_version_pangolin pangolin --update-data --datadir ${PWD}/$(date '+%Y%m%d')/
        echo "Pangolin database UPDATED."
    fi
    cd -

    # Updating config file
    echo "Updating $CONFIG_FILE file..."
    sed -i "s|pangolin:4.2--pyhdfd78af_1|$latest_version_pangolin|" "$CONFIG_FILE"
    sed -i "s|--datadir XXXX|--datadir $(ls -dt /data/bi/references/pangolin/*/ | head -n 1)|" "$CONFIG_FILE"
    echo "File $CONFIG_FILE UPDATED."

    # Updating params file
    echo "Updating $PARAMS_FILE file..."
    sed -i "s|skip_pangolin: true|skip_pangolin: false|" "$PARAMS_FILE"
    echo "File $PARAMS_FILE UPDATED."

}

# Updating Nextclade. Checks last image available and if is already downloaded. If not, downloads it. Update related config files with nextclade info
update_nextclade() {
    echo "Checking Nextclade container version..."
    url=$(curl -s "https://depot.galaxyproject.org/singularity/")
    latest_version_nextclade=$(echo "$url" | grep -oP 'nextclade:[^"]+' | sort -V | tail -n 1 | awk -F'>' '{print $1}' | sed 's/<\/a//')
    echo "Latest version available of Nextclade: $latest_version_nextclade."

    echo "Checking if latest version of Nextclade image is already downloaded..."
    if [ -e "/data/bi/scratch_tmp/bi/singularity-images/$latest_version_nextclade" ]; then
        echo "File $latest_version_nextclade already downloaded."
    else
        echo "Downloading $latest_version_nextclade file..."
        wget -P "/data/bi/scratch_tmp/bi/singularity-images/" "https://depot.galaxyproject.org/singularity/$latest_version_nextclade"
        echo "$latest_version_nextclade file succesfully downloaded."
    fi

    # Extracting the current Nextclade data TAG
    echo "Extracting Nextclade data TAG..."
    nextclade_tag=$(curl -s "https://github.com/nextstrain/nextclade_data/tags" | grep "chore: release" | head -n 1 | cut -d ' ' -f12)
    echo "Latest Nextclade dataset version TAG: $nextclade_tag."

    # Updating config file
    echo "Updating $CONFIG_FILE file..."
    sed -i "s|nextclade:2.13.1--h9ee0642_0|$latest_version_nextclade|" "$CONFIG_FILE"
    echo "File $CONFIG_FILE UPDATED."

    # Updating params file
    echo "Updating $PARAMS_FILE file..."
    sed -i "s|skip_nextclade: true|skip_nextclade: false|" "$PARAMS_FILE"
    echo "nextclade_dataset_name: '$virus_tag'" >> $PARAMS_FILE
    echo "nextclade_dataset: false" >> $PARAMS_FILE
    echo "nextclade_dataset_tag: '$nextclade_tag'" >> $PARAMS_FILE
    echo "File $PARAMS_FILE UPDATED."
}

# Checks if fasta and gff references are downloaded. If not, it downloades them (and create family folder if neccesary)
check_references() {
    echo "Processing reference: ${ref}."

    # Obtaining family information
    obtain_family() {
        organism_id=$(curl -s "https://www.ncbi.nlm.nih.gov/nuccore/${ref}" | grep -o 'ORGANISM=[0-9]\+' | head -n 1 | awk -F '=' '{print $2}')
        family=$(curl -s "https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=${organism_id}" | grep -o 'TITLE="family">.*<' | awk -F 'TITLE="family">' '{print $2}' | cut -d '<' -f 1 | tr '[:upper:]' '[:lower:]')
        if [ -z $family ]; then
            family=$(curl -s "https://www.ncbi.nlm.nih.gov/Taxonomy/Browser/wwwtax.cgi?id=${organism_id}" | grep -o 'ALT="family">.*<' | awk -F 'ALT="family">' '{print $2}' | cut -d '<' -f 1 | tr '[:upper:]' '[:lower:]')
        fi
        echo "Reference $ref organism belongs to $family family."
    }

    # Check if FASTA sequence is already downloaded
    REF_FASTA=$(find . -maxdepth 2 -type f -name "${ref}.fa*")
    if [ -z $REF_FASTA ]; then
        obtain_family
        if [ ! -e "./$family" ]; then
            echo Creating new directory: /data/bi/references/virus/${family}/
            mkdir ./${family}/
        else
            echo "Directory /data/bi/references/virus/${family}/ ALREADY EXISTS."
        fi
        echo "Downloading ${ref}.fasta file..."
        wget -q -O "./${family}/${ref}.fasta" "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=${ref}&rettype=fasta&retmode=text"
        REF_FASTA="/data/bi/references/virus/${family}/${ref}.fasta"
        echo "File ${ref}.fasta downloaded in $REF_FASTA."
    else
        echo "File ${ref}.fasta is ALREADY available in $REF_FASTA."
    fi

    # Check if GFF file is already downloaded
    REF_GFF=$(find . -maxdepth 2 -type f -name "${ref}.gff*")
    if [ -z $REF_GFF ]; then
        if [ ! -v family ]; then obtain_family; fi
        if [ ! -e "./$family" ]; then
            echo Creating new directory: /data/bi/references/virus/${family}/
            mkdir ./${family}/
        fi
        echo "Downloading ${ref}.gff file..."
        wget -q -O "./${family}/${ref}.gff" "https://www.ncbi.nlm.nih.gov/sviewer/viewer.cgi?db=nuccore&report=gff3&id=${ref}"
        REF_GFF="/data/bi/references/virus/${family}/${ref}.gff"
        echo "File ${ref}.gff downloaded in $REF_GFF."
    else
        echo "File ${ref}.gff is ALREADY available in $REF_GFF."
    fi

    unset family
}
####################################

# Setting work variables
CONFIG_FILE="../../DOC/viralrecon.config"
PARAMS_FILE="../../DOC/viralrecon_params.yml"

# Setting the type of analysis
echo Please specify the type of analysis.
echo 1. METAGENOMICS
echo 2. AMPLICONS
while true; do
    read ANALYSIS_TYPE
    if [ "$ANALYSIS_TYPE" == "1" ]; then
        ANALYSIS_TYPE="METAGENOMIC"
        echo "You selected $ANALYSIS_TYPE analysis."
        break
    elif [ "$ANALYSIS_TYPE" == "2" ]; then
        ANALYSIS_TYPE="AMPLICONS"
        echo "You selected $ANALYSIS_TYPE analysis."
        break
    else
        echo "Invalid input. Please enter 1 or 2."
    fi
done

# Setting samples_ref.txt file
read -p "Is samples_ref.txt file already prepared? [y/N]: " samples_ref_prepared
if [ "$samples_ref_prepared" == "y" ]; then 
    echo "File samples_ref.txt READY."
else
    : > samples_ref.txt
    echo "File samples_ref NOT prepared."
    while [ -z "$host" ] || [ -z "$reference" ] || [ "$answer" = "n" ]; do
        read -p "Please specify the host: " host
        read -p "Please specify the reference: " reference
        read -p "Are host [${host^^}] and reference [$reference] correct? [Y/n]: " answer
    done
    while read in; do echo -e "${in}\t${reference}\t${host^^}" >> samples_ref.txt; done < samples_id.txt
    echo "File samples_ref.txt READY."
fi


# Preparing enviroment for METAGENOMIC analysis
if [ "$ANALYSIS_TYPE" = "METAGENOMIC" ]; then

    # Nextclade is able to analyze monkeypox virus
    read -p "Do the sequences correspond to monkeypox virus (MPV)? [y/N]: " monkeypox
    if [ "$monkeypox" == "y" ]; then

        virus_tag='mpox'
        # Update Nextclade
        update_nextclade

    fi

# Preparing enviroment for AMPLICONS analysis
else

    sed -i "s|protocol: 'metagenomic'|protocol: 'amplicon'|" $PARAMS_FILE

    echo Please specify the organism to which the sequences correspond.
    echo 1. SARS-CoV-2
    echo 2. RSV
    echo 3. Other
    while true; do
        read virus_ref
        if [ "$virus_ref" == "1" ]; then
            virus_ref="SARS-CoV-2"
            echo "You selected $virus_ref virus."
            break
        elif [ "$virus_ref" == "2" ]; then
            virus_ref="RSV"
            echo "You selected $virus_ref virus."
            break
        elif [ "$virus_ref" == "3" ]; then
            virus_ref="Other"
            echo "You selected $virus_ref virus."
            break
        else
            echo "Invalid input. Please select a valid number"
        fi
    done

    # Preparing the environment for SARS-CoV-2 analysis
    if [ "$virus_ref" == "SARS-CoV-2" ]; then
        virus_tag='sars-cov-2'
        # Update Nextclade and Pangolin
        update_nextclade
        update_pangolin

        echo "primer_bed: '/data/bi/references/virus/2019-nCoV/amplicons/NC_045512.2/V4.1/artic_v4-1_ncov-2019-primer.scheme.bed'" >> $PARAMS_FILE

    elif [ "$virus_ref" == "RSV" ]; then       
        # Update Nextclade
        update_nextclade
        sed -i '/^nextclade_dataset_name/d' $PARAMS_FILE
        sed -i "s|skip_assembly: true|skip_assembly: false|" "$PARAMS_FILE"

        echo "Remember to provide the complete route to primer_bed and primer_fasta files, and specify the nextclade_dataset_name in every sbatch file before running the pipeline"

    else
        echo "primer_bed: '../REFERENCES/XXXX'" >> $PARAMS_FILE
        echo "Remember to provide the complete route to PRIMER_BED file in $PARAMS_FILE file before running the pipeline"
    fi

fi

mkdir -p 00-reads
cat samples_ref.txt | cut -f3 | sort -u | while read in; do echo ${in}; done > host_list.tmp
i=1; cat host_list.tmp | while read in
do
    FOLDER_NAME=$(echo $(date '+%Y%m%d')_ANALYSIS0${i}_${ANALYSIS_TYPE}_${in})
    mkdir ${FOLDER_NAME}
    cp create_summary_report.sh ${FOLDER_NAME}/
    cp deduplicate_long_table.sh ${FOLDER_NAME}/
    cp percentajeNs.py ${FOLDER_NAME}/
    grep -i ${in} samples_ref.txt | cut -f1,2 > ${FOLDER_NAME}/samples_ref.txt
    echo "ln -s ../00-reads ." > ${FOLDER_NAME}/lablog
    printf "ln -s ../samples_id.txt .\n\n" >> ${FOLDER_NAME}/lablog
    echo "#module load Nextflow singularity" >> ${FOLDER_NAME}/lablog
    echo "" >> ${FOLDER_NAME}/lablog
    printf 'scratch_dir=$(echo $PWD | sed "s/\/data\/bi\/scratch_tmp/\/scratch/g")\n\n' >> ${FOLDER_NAME}/lablog
    cut -f2 ${FOLDER_NAME}/samples_ref.txt | sort -u | while read ref
    do
        echo "sample,fastq_1,fastq_2" > ${FOLDER_NAME}/samplesheet_${ref}.csv
        grep -i ${ref} ${FOLDER_NAME}/samples_ref.txt | while read samples
        do
            arr=($samples); echo "${arr[0]},00-reads/${arr[0]}_R1.fastq.gz,00-reads/${arr[0]}_R2.fastq.gz" >> ${FOLDER_NAME}/samplesheet_${ref}.csv
        done
        check_references
        echo "cat <<EOF > ${ref}_viralrecon.sbatch" >> ${FOLDER_NAME}/lablog
        echo "#!/bin/sh" >> ${FOLDER_NAME}/lablog
        echo "#SBATCH --ntasks 1" >> ${FOLDER_NAME}/lablog
        echo "#SBATCH --cpus-per-task 2" >> ${FOLDER_NAME}/lablog
        echo "#SBATCH --mem 4G" >> ${FOLDER_NAME}/lablog
        echo "#SBATCH --time 2:00:00" >> ${FOLDER_NAME}/lablog
        echo "#SBATCH --partition middle_idx" >> ${FOLDER_NAME}/lablog
        echo "#SBATCH --output ${ref}_$(date '+%Y%m%d')_viralrecon.log" >> ${FOLDER_NAME}/lablog
        printf "#SBATCH --chdir \$scratch_dir\n\n" >> ${FOLDER_NAME}/lablog
        printf 'export NXF_OPTS="-Xms500M -Xmx4G"\n\n' >> ${FOLDER_NAME}/lablog
        echo "nextflow run /data/bi/pipelines/nf-core-viralrecon-2.6.0/workflow/main.nf \\\\" >> ${FOLDER_NAME}/lablog
        echo "          -c ${CONFIG_FILE} \\\\" >> ${FOLDER_NAME}/lablog
        echo "          -params-file ${PARAMS_FILE} \\\\" >> ${FOLDER_NAME}/lablog
        echo "          --input samplesheet_${ref}.csv \\\\" >> ${FOLDER_NAME}/lablog
        echo "          --outdir ${ref}_$(date '+%Y%m%d')_viralrecon_mapping \\\\" >> ${FOLDER_NAME}/lablog
        echo "          --fasta ${REF_FASTA} \\\\" >> ${FOLDER_NAME}/lablog
        echo "          --gff ${REF_GFF} \\\\" >> ${FOLDER_NAME}/lablog
        if [ $virus_ref == 'RSV' ]; then
            echo "          --primer_bed ../../REFERENCES/XXXX \\\\" >> ${FOLDER_NAME}/lablog
            echo "          --primer_fasta ../../REFERENCES/XXXX \\\\" >> ${FOLDER_NAME}/lablog
            echo "          --nextclade_dataset_name 'rsv_X' \\\\" >> ${FOLDER_NAME}/lablog
        echo "          -resume" >> ${FOLDER_NAME}/lablog
        printf "EOF\n\n" >> ${FOLDER_NAME}/lablog
        printf "echo 'sbatch ${ref}_viralrecon.sbatch' > _01_run_${ref}_viralrecon.sh\n\n" >> ${FOLDER_NAME}/lablog
    done
  echo "#conda activate python3" >> ${FOLDER_NAME}/lablog

  cp _02_create_run_percentage_Ns.sh ${FOLDER_NAME}/
  printf 'echo "bash create_summary_report.sh" > _04_create_stats_table.sh\n\n' >> ${FOLDER_NAME}/lablog
  cp create_assembly_stats.R ${FOLDER_NAME}/
  echo "#module load R/4.2.1" >> ${FOLDER_NAME}/lablog
  printf 'echo "Rscript create_assembly_stats.R" > _05_create_stats_assembly.sh\n\n' >> ${FOLDER_NAME}/lablog
  printf 'echo "bash deduplicate_long_table.sh" > _06_deduplicate_long_table.sh\n\n' >> ${FOLDER_NAME}/lablog

    i=$((i+1))
done
rm host_list.tmp
rm create_summary_report.sh
rm deduplicate_long_table.sh
rm percentajeNs.py
rm _02_create_run_percentage_Ns.sh
mv DATE_ANALYSIS0X_MAG $(date '+%Y%m%d')_ANALYSIS0X_MAG
cd 00-reads; cat ../samples_id.txt | xargs -I % echo "ln -s ../../RAW/%_*R1*.fastq.gz %_R1.fastq.gz" | bash; cat ../samples_id.txt | xargs -I % echo "ln -s ../../RAW/%_*R2*.fastq.gz %_R2.fastq.gz" | bash; cd -
